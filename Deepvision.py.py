# -*- coding: utf-8 -*-
"""INFOSYS_SPRINGBOARD_PROJECT_DEEPVISION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HXX11yFANlNJfhGy4P5_WnTyGj53mLs0
"""

!pip install torch torchvision numpy scipy matplotlib scikit-learn opencv-python streamlit h5py pyngrok plotly --quiet

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %%writefile dataset.py
# import os, cv2
# import numpy as np
# import torch
# from torch.utils.data import Dataset
# from torchvision import transforms as T
# import scipy.io as sio
# from scipy.ndimage import gaussian_filter
# 
# def generate_density_map(img_shape, points, sigma=4):
#     d = np.zeros(img_shape, dtype=np.float32)
#     for x, y in points:
#         if int(y) < img_shape[0] and int(x) < img_shape[1]:
#             d[int(y), int(x)] = 1
#     return gaussian_filter(d, sigma=sigma)
# 
# class ShanghaiDataset(Dataset):
#     def __init__(self, img_dir, gt_dir, resize=(512, 512)):
#         self.img_dir = img_dir
#         self.gt_dir = gt_dir
#         self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]
#         self.resize = resize
#         self.transform = T.Compose([
#             T.ToTensor(),
#             T.Normalize(mean=[0.485, 0.456, 0.406],
#                         std=[0.229, 0.224, 0.225])
#         ])
#     def __len__(self):
#         return len(self.img_files)
#     def __getitem__(self, idx):
#         img_path = os.path.join(self.img_dir, self.img_files[idx])
#         img = cv2.imread(img_path)
#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#         h, w = img.shape[:2]
#         img_resized = cv2.resize(img, self.resize)
# 
#         base = os.path.splitext(self.img_files[idx])[0]
#         gt_path = os.path.join(self.gt_dir, f"GT_{base}.mat")
#         mat = sio.loadmat(gt_path)
#         points = mat["image_info"][0,0][0,0][0]
#         scale_x, scale_y = self.resize[0]/w, self.resize[1]/h
#         pts_scaled = [(p[0]*scale_x, p[1]*scale_y) for p in points]
# 
#         density = generate_density_map(
#             (self.resize[1]//8, self.resize[0]//8),
#             [(px/8, py/8) for px, py in pts_scaled]
#         )
#         img_tensor = self.transform(img_resized)
#         d_tensor = torch.from_numpy(density).unsqueeze(0).float()
#         return img_tensor, d_tensor, img_resized, density

# Commented out IPython magic to ensure Python compatibility.
# %%writefile model.py
# import torch
# import torch.nn as nn
# import torchvision.models as models
# 
# class CSRNet(nn.Module):
#     def __init__(self):
#         super(CSRNet, self).__init__()
#         vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)
#         self.frontend = nn.Sequential(*list(vgg.features.children())[:23])
#         self.backend = nn.Sequential(
#             nn.Conv2d(512, 256, 3, padding=2, dilation=2), nn.ReLU(inplace=True),
#             nn.Conv2d(256, 128, 3, padding=2, dilation=2), nn.ReLU(inplace=True),
#             nn.Conv2d(128, 64, 3, padding=2, dilation=2), nn.ReLU(inplace=True),
#             nn.Conv2d(64, 1, 1)
#         )
#     def forward(self, x):
#         x = self.frontend(x)
#         x = self.backend(x)
#         return x

# Commented out IPython magic to ensure Python compatibility.
# %%writefile train.py
# import torch, torch.nn as nn, torch.optim as optim
# from torch.utils.data import DataLoader, Subset
# from dataset import ShanghaiDataset
# from model import CSRNet
# 
# IMG_DIR = "/content/drive/MyDrive/ShanghaiTech/part_B/train_data/images"
# GT_DIR = "/content/drive/MyDrive/ShanghaiTech/part_B/train_data/ground-truth"
# 
# dataset = ShanghaiDataset(IMG_DIR, GT_DIR)
# demo_dataset = Subset(dataset, [0,1])
# dataloader = DataLoader(demo_dataset, batch_size=1, shuffle=True)
# 
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model = CSRNet().to(device)
# criterion = nn.MSELoss()
# optimizer = optim.Adam(model.parameters(), lr=1e-5)
# 
# for epoch in range(1):
#     epoch_loss = 0
#     for imgs, dens, _, _ in dataloader:
#         imgs, dens = imgs.to(device), dens.to(device)
#         out = model(imgs)
#         loss = criterion(out, dens)
#         optimizer.zero_grad(); loss.backward(); optimizer.step()
#         epoch_loss += loss.item()
#     print(f"Demo Epoch Loss: {epoch_loss/len(dataloader):.4f}")
# 
# torch.save(model.state_dict(), "csrnet_demo.pth")
# print("‚úÖ Demo weights saved as csrnet_demo.pth")

!python train.py

import torch, matplotlib.pyplot as plt
from model import CSRNet
from dataset import ShanghaiDataset

IMG_DIR = "/content/drive/MyDrive/ShanghaiTech/part_B/train_data/images"
GT_DIR = "/content/drive/MyDrive/ShanghaiTech/part_B/train_data/ground-truth"

dataset = ShanghaiDataset(IMG_DIR, GT_DIR)
img, gt_density, orig, gt = dataset[1]

model = CSRNet()
model.load_state_dict(torch.load("csrnet_demo.pth", map_location="cpu"))
model.eval()

with torch.no_grad():
    pred = model(img.unsqueeze(0)).squeeze().numpy()

plt.figure(figsize=(15,5))
plt.subplot(1,3,1); plt.imshow(orig); plt.title("Original")
plt.subplot(1,3,2); plt.imshow(gt, cmap="jet"); plt.title(f"GT (Count: {gt.sum():.1f})")
plt.subplot(1,3,3); plt.imshow(pred, cmap="jet"); plt.title(f"Predicted (Count: {pred.sum():.1f})")
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import torch, numpy as np
# from PIL import Image
# from torchvision import transforms as T
# import matplotlib.pyplot as plt
# import plotly.graph_objects as go
# import os, smtplib, datetime
# from model import CSRNet
# 
# # -----------------------------
# # PAGE CONFIG
# # -----------------------------
# st.set_page_config(
#     page_title="üö¶ DeepVision Crowd Monitor",
#     layout="wide",
#     initial_sidebar_state="expanded",
#     page_icon="üö¶"
# )
# 
# # -----------------------------
# # CUSTOM STYLING
# # -----------------------------
# st.markdown("""
# <style>
# body {
#     background: linear-gradient(135deg, #0f2027, #203a43, #2c5364);
#     color: #f1f1f1;
#     font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
# }
# .header-container {
#     text-align: center;
#     padding: 35px;
#     margin-bottom: 25px;
#     border-radius: 25px;
#     background: linear-gradient(270deg, #667eea, #764ba2, #667eea);
#     background-size: 600% 600%;
#     animation: gradientBG 15s ease infinite;
#     box-shadow: 0 15px 40px rgba(0,0,0,0.5);
# }
# @keyframes gradientBG {0% {background-position:0% 50%;}50% {background-position:100% 50%;}100% {background-position:0% 50%;}}
# .header-container h1 {
#     font-size: 3em;
#     color: black;
#     font-weight: bold;
#     animation: pulseText 2s infinite;
# }
# @keyframes pulseText {0% {transform: scale(1);}50% {transform: scale(1.05);}100% {transform: scale(1);}}
# .header-container p {font-size: 1.2em; color: #f1f1f1;}
# .card {
#     background: rgba(255,255,255,0.05);
#     backdrop-filter: blur(10px);
#     padding: 25px;
#     border-radius: 20px;
#     box-shadow: 0 15px 40px rgba(0,0,0,0.5);
#     transition: transform 0.3s ease, box-shadow 0.3s ease;
# }
# .card:hover {transform: translateY(-7px); box-shadow: 0 20px 50px rgba(0,0,0,0.7);}
# .card h3, .card h2, .card p {color: black; font-weight: bold;}
# .alert-badge {
#     background: linear-gradient(135deg,#ff416c,#ff4b2b);
#     color: #fff;
#     font-weight: bold;
#     padding: 12px 25px;
#     border-radius: 20px;
#     text-align: center;
#     animation: pulse 1.5s infinite;
# }
# @keyframes pulse {0% { transform: scale(1); opacity:1; }50% { transform: scale(1.08); opacity:0.85; }100% { transform: scale(1); opacity:1; }}
# [data-testid="stSidebar"] {background: linear-gradient(180deg,#203a43,#0f2027); color: #f1f1f1; font-weight: 500;}
# [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3 {color: #fff;}
# .stButton>button {
#     background: linear-gradient(90deg,#ff416c,#ff4b2b);
#     color:white;
#     font-weight:bold;
#     border-radius:12px;
#     padding:12px 25px;
#     margin-top:10px;
#     transition: transform 0.2s ease, box-shadow 0.2s ease;
# }
# .stButton>button:hover {transform: translateY(-3px); box-shadow: 0 10px 25px rgba(0,0,0,0.6);}
# .stFileUploader>div>div>input {border-radius: 15px; padding: 5px;}
# .plotly-graph-div {background: rgba(0,0,0,0.05) !important; border-radius: 20px;}
# .footer {text-align: center; color: #9ca3af; margin-top: 30px; font-size: 0.9em;}
# </style>
# """, unsafe_allow_html=True)
# 
# # -----------------------------
# # LOAD MODEL
# # -----------------------------
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model = CSRNet().to(device)
# model.load_state_dict(torch.load("csrnet_demo.pth", map_location=device))
# model.eval()
# transform = T.Compose([T.Resize((512,512)), T.ToTensor(), T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])])
# 
# # -----------------------------
# # EMAIL CREDENTIALS
# # -----------------------------
# EMAIL_USER = "727724eucy048@skcet.ac.in"
# EMAIL_PASS = "----------------"
# ALERT_EMAIL = "maanisha504@gmail.com"
# 
# def send_email_alert(subject, body):
#     try:
#         with smtplib.SMTP("smtp.gmail.com", 587) as server:
#             server.starttls()
#             server.login(EMAIL_USER, EMAIL_PASS)
#             server.sendmail(EMAIL_USER, ALERT_EMAIL, f"Subject: {subject}\n\n{body}")
#         return True
#     except Exception as e:
#         return str(e)
# 
# # -----------------------------
# # HEADER
# # -----------------------------
# st.markdown("""
# <div class='header-container'>
# <h1>üö¶ DeepVision Crowd Monitor</h1>
# <p>AI-Powered Real-Time Crowd Density Analysis & Safety Management</p>
# </div>
# """, unsafe_allow_html=True)
# 
# # -----------------------------
# # SIDEBAR METRICS
# # -----------------------------
# st.sidebar.markdown("## üìä Quick Stats")
# st.sidebar.markdown(f"- Total Images Processed: 0")
# st.sidebar.markdown(f"- Crowd Threshold: 200")
# st.sidebar.markdown(f"- Safe Density: 0-70%")
# st.sidebar.markdown(f"- Critical Density: >70%")
# 
# # -----------------------------
# # UPLOAD IMAGE
# # -----------------------------
# uploaded = st.file_uploader("üì∑ Upload Crowd Image", type=["jpg","png","jpeg"])
# if uploaded:
#     image = Image.open(uploaded).convert("RGB")
#     img_tensor = transform(image).unsqueeze(0).to(device)
# 
#     with torch.no_grad():
#         density_map = model(img_tensor).squeeze().cpu().numpy()
#     count = int(np.sum(density_map))
#     density_percentage = min(100, round(count/300*100,1))
#     risk = "HIGH" if density_percentage>70 else "LOW"
# 
#     if risk=="HIGH":
#         st.markdown("<div class='alert-badge'>üö® LIVE ALERT!</div>", unsafe_allow_html=True)
# 
#     col1, col2, col3 = st.columns(3)
#     metrics = [
#         ("üë• Crowd Count", count, f"{'Within safe limit' if risk=='LOW' else max(0,count-200)+' above threshold'}"),
#         ("üìä Density Level", f"{density_percentage}%", ""),
#         ("‚ö†Ô∏è Risk Status", risk, "Immediate Action Required" if risk=="HIGH" else "Normal")
#     ]
#     for col, (title, val, desc) in zip([col1,col2,col3], metrics):
#         col.markdown(f"""
#         <div class='card'>
#             <h3>{title}</h3>
#             <h2>{val}</h2>
#             <p>{desc}</p>
#         </div>
#         """, unsafe_allow_html=True)
# 
#     st.subheader("üîç Crowd Density Visualization")
#     overlay = Image.fromarray(np.uint8(plt.cm.plasma(density_map/np.max(density_map))*255))
#     overlay = overlay.resize(image.size)
#     combined = Image.blend(image, overlay.convert("RGB"), alpha=0.5)
#     st.image(combined, caption="Heatmap Overlay", use_column_width=True)
# 
#     if count > 200:
#         st.error("üö® Overcrowding detected! Sending Email...")
#         send_email_alert("üö® Crowd Alert", f"Overcrowding Detected! Count: {count}")
# 
#     st.subheader("üìà Crowd Trend Analysis")
#     times = ['10:00','10:30','11:00','11:30','12:00','12:30','13:00','13:30','14:00']
#     counts_list = [120,135,145,160,180,195,210,235,count]
#     threshold = [200]*len(times)
#     fig = go.Figure()
#     fig.add_trace(go.Scatter(x=times, y=counts_list, mode='lines+markers', name='Crowd Count', line=dict(color='#667eea', width=4), marker=dict(size=12, color=counts_list, colorscale='Viridis', showscale=True)))
#     fig.add_trace(go.Scatter(x=times, y=threshold, mode='lines', name='Threshold', line=dict(color='#ff4b2b', width=3, dash='dash')))
#     fig.update_layout(paper_bgcolor='#111827', plot_bgcolor='#111827', font_color='white', height=450, margin=dict(l=20,r=20,t=20,b=20))
#     st.plotly_chart(fig, use_container_width=True)
# 
# # -----------------------------
# # MANUAL EMAIL ALERT
# # -----------------------------
# st.subheader("üì© Send Manual Test Email")
# subject = st.text_input("Subject", "Test Alert")
# body = st.text_area("Message", "This is a test alert from Streamlit App!")
# if st.button("Send Email"):
#     result = send_email_alert(subject, body)
#     if result == True:
#         st.success(f"‚úÖ Email sent to {ALERT_EMAIL}")
#     else:
#         st.error(f"‚ùå Failed: {result}")
# 
# # -----------------------------
# # RECOMMENDATIONS PANEL
# # -----------------------------
# st.subheader("üí° Recommended Actions")
# st.markdown("""
# <div class='card'>
# - üö® Deploy additional security personnel immediately<br>
# - üö™ Activate controlled entry/exit protocols<br>
# - üì¢ Use PA system to manage crowd flow<br>
# - ‚ö†Ô∏è Prepare emergency evacuation routes
# </div>
# """, unsafe_allow_html=True)
# 
# # -----------------------------
# # FOOTER
# # -----------------------------
# st.markdown(f"<p class='footer'>Last Updated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>", unsafe_allow_html=True)

!pkill ngrok

from pyngrok import ngrok

# Kill previous tunnels
ngrok.kill()

# Start new tunnel
public_url = ngrok.connect(8501)
print(public_url)